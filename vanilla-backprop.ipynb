{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we write a function to perform gradient descent using backpropagation for a neural network with a single hidden layer and an arbitrary number of nodes.\n",
    "We assume the activation function in each layer is the same and the loss function is the following variation of squared error:\n",
    "$$ L(\\mathbf{y}, \\tilde{\\mathbf{y}}) = \\frac{1}{2} \\Vert \\mathbf{y} - \\tilde{\\mathbf{y}} \\Vert^2 ,$$\n",
    "Note that this is the loss of only one sample. The total loss is given by\n",
    "$$ \\frac{1}{n} \\sum_{i=1}^n L(\\mathbf{y}_i, \\tilde{\\mathbf{y}_i}) ,$$\n",
    "where $n$ is the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5976995968311531, 0.6609547685319225, 1), (0.029321747981573387, 0.4677344158515626, 1), (0.2400893827846332, 0.2972874413585408, 1), (0.8066115183245178, 0.8612229954363302, 1), (0.3969629550341518, 0.7016722795067178, 1), (0.8263601513499168, 0.9304959215688829, 1), (0.41275037100029843, 0.3774477434359702, 1), (0.17093092376920038, 0.3727729985532132, 1), (0.17356685864929178, 0.07996250139300876, 1), (0.40942081071909786, 0.7160155267619446, 1), (0.5863613686649145, 0.06248217765120345, 0), (0.9246752988867835, 0.5729423548782724, 0), (0.5631105033974596, 0.16241746637457188, 0), (0.45271672270523244, 0.09697494980860077, 0), (0.8070444596721129, 0.5681277681043985, 0), (0.5729263154498813, 0.1917612371801709, 0), (0.9349021656390322, 0.12767398715146383, 0), (0.7899932300604782, 0.3508912200573031, 0), (0.8602576877717567, 0.10567249821983538, 0), (0.9386594987544427, 0.056685469758344764, 0)]\n",
      "[[0.5976996  0.66095477 1.        ]\n",
      " [0.02932175 0.46773442 1.        ]\n",
      " [0.24008938 0.29728744 1.        ]\n",
      " [0.80661152 0.861223   1.        ]\n",
      " [0.39696296 0.70167228 1.        ]\n",
      " [0.82636015 0.93049592 1.        ]\n",
      " [0.41275037 0.37744774 1.        ]\n",
      " [0.17093092 0.372773   1.        ]\n",
      " [0.17356686 0.0799625  1.        ]\n",
      " [0.40942081 0.71601553 1.        ]\n",
      " [0.58636137 0.06248218 0.        ]\n",
      " [0.9246753  0.57294235 0.        ]\n",
      " [0.5631105  0.16241747 0.        ]\n",
      " [0.45271672 0.09697495 0.        ]\n",
      " [0.80704446 0.56812777 0.        ]\n",
      " [0.57292632 0.19176124 0.        ]\n",
      " [0.93490217 0.12767399 0.        ]\n",
      " [0.78999323 0.35089122 0.        ]\n",
      " [0.86025769 0.1056725  0.        ]\n",
      " [0.9386595  0.05668547 0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_class_1 = []\n",
    "while len(samples_class_1) < 10:\n",
    "    x = np.random.rand()\n",
    "    y = np.random.rand()\n",
    "    if y >= x**2:\n",
    "        samples_class_1.append((x, y, 1))\n",
    "\n",
    "samples_class_0 = []\n",
    "while len(samples_class_0) < 10:\n",
    "    x = np.random.rand()\n",
    "    y = np.random.rand()\n",
    "    if y < x**2:\n",
    "        samples_class_0.append((x, y, 0))\n",
    "\n",
    "samples = samples_class_1 + samples_class_0\n",
    "print(samples)\n",
    "\n",
    "samples_array = np.array(samples)\n",
    "print(samples_array)\n",
    "\n",
    "class_0 = samples_array[samples_array[:, 2] == 0]\n",
    "class_1 = samples_array[samples_array[:, 2] == 1]\n",
    "\n",
    "plt.scatter(class_0[:, 0], class_0[:, 1], color='blue', marker='o', label='Class 0')\n",
    "plt.scatter(class_1[:, 0], class_1[:, 1], color='red', marker='x', label='Class 1')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Samples Plot')\n",
    "plt.show()\n",
    "\n",
    "train_points = samples_array[:, :2]\n",
    "train_labels = samples_array[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def loss(y_true, y_pred):\n",
    "    return 0.5 * np.linalg.norm(y_true - y_pred) ** 2\n",
    "\n",
    "# activation functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network\n",
    "num_input = 2 \n",
    "num_hidden = 3 \n",
    "num_output = 1\n",
    "activation = sigmoid \n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return randomized model weights $W^2, W^3$ and biases ${\\bf b}^2, {\\bf b}^3$ in the range $[0,1)$. Define these outputs as `W2`, `W3`, `b2`, and `b3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2: [[0.41309675 0.48482366]\n",
      " [0.6643742  0.93509573]\n",
      " [0.08014594 0.90636683]]\n",
      "b2: [0.64206805 0.61634558 0.27245124]\n",
      "W3: [[0.40400426 0.55206189 0.47237379]]\n",
      "b3: [0.69449319]\n"
     ]
    }
   ],
   "source": [
    "def model_compile(num_input, num_hidden, num_output, activation, learning_rate):\n",
    "    W2 = np.random.rand(num_hidden, num_input)\n",
    "    W3 = np.random.rand(num_output, num_hidden)\n",
    "    b2 = np.random.rand(num_hidden)\n",
    "    b3 = np.random.rand(num_output)\n",
    "    return W2, b2, W3, b3\n",
    "\n",
    "\n",
    "W2, b2, W3, b3 = model_compile(num_input, num_hidden, num_output, activation, learning_rate)\n",
    "print(f'W2: {W2}\\nb2: {b2}\\nW3: {W3}\\nb3: {b3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass: it applies the model to a point to predict its label. The function output the preactivated and activated neurons in layers 2 and 3--i.e., $\\mathbf{z}^2$, $\\mathbf{a}^2$, $\\mathbf{z}^3$, and $\\mathbf{a}^3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z2: [1.20942232 1.63149775 0.91942192]\n",
      "A2: [0.77019672 0.83637471 0.7149243 ]\n",
      "Z3: [1.80509805]\n",
      "A3: [0.85876839]\n"
     ]
    }
   ],
   "source": [
    "def forward_pass(X, W2, b2, W3, b3, activation):\n",
    "    Z2 = np.dot(W2, X) + b2\n",
    "    A2 = activation(Z2)\n",
    "    Z3 = np.dot(W3, A2) + b3\n",
    "    A3 = activation(Z3)\n",
    "    return Z2, A2, Z3, A3\n",
    "\n",
    "\n",
    "Z2, A2, Z3, A3 = forward_pass(train_points[0], W2, b2, W3, b3, activation)\n",
    "print(f'Z2: {Z2}\\nA2: {A2}\\nZ3: {Z3}\\nA3: {A3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    deriv = sigmoid(x) * (1 - sigmoid(x))\n",
    "    return deriv\n",
    "\n",
    "def ReLU_derivative(x):\n",
    "    deriv = np.zeros_like(x)\n",
    "    for i in range(len(x)):\n",
    "        if x[i] >= 0:\n",
    "            deriv[i] = 1\n",
    "    return deriv\n",
    "\n",
    "x = np.array([1,2,3,-1,-2,0])\n",
    "print(ReLU_derivative(x))\n",
    "\n",
    "\n",
    "if activation == sigmoid:\n",
    "    activation_derivative = sigmoid_derivative\n",
    "elif activation == ReLU:\n",
    "    activation_derivative = ReLU_derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the gradient of the loss function with respect to the final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14123161]\n"
     ]
    }
   ],
   "source": [
    "def loss_grad_final_layer(y, A3):\n",
    "    grad = A3 - y\n",
    "    return grad \n",
    "\n",
    "\n",
    "print(loss_grad_final_layer(train_labels[0], A3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the backward pass to compute the gradient vector of the loss function with respect to the model weights and biases for a **single input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW2: [[-0.00073209 -0.00080957]\n",
      " [-0.0007735  -0.00085536]\n",
      " [-0.00098566 -0.00108998]]\n",
      "db2: [-0.00122485 -0.00129413 -0.0016491 ]\n",
      "dW3: [[-0.01319294 -0.01432652 -0.01224616]]\n",
      "db3: [-0.01712931]\n"
     ]
    }
   ],
   "source": [
    "def backpropagation(X, Y, W2, b2, W3, b3, activation, activation_derivative):\n",
    "    Z2, A2, Z3, A3 = forward_pass(X, W2, b2, W3, b3, activation)\n",
    "    d3 = loss_grad_final_layer(Y, A3) * activation_derivative(Z3)\n",
    "    dW3 = np.outer(d3, A2)\n",
    "    db3 = d3\n",
    "    d2 = np.dot(W3.T, d3) * activation_derivative(Z2)\n",
    "    dW2 = np.outer(d2, X)\n",
    "    db2 = d2\n",
    "    \n",
    "    return dW2, db2, dW3, db3\n",
    "\n",
    "\n",
    "dW2, db2, dW3, db3 = backpropagation(train_points[0], train_labels[0], W2, b2, W3, b3, activation, activation_derivative)\n",
    "print(f'dW2: {dW2}\\ndb2: {db2}\\ndW3: {dW3}\\ndb3: {db3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the backward pass to compute the gradient vector of the loss function with respect to the model weights and biases for the **total loss function** (for all of our training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW2: [[0.00282001 0.00054931]\n",
      " [0.00334386 0.00062683]\n",
      " [0.00404712 0.00081915]]\n",
      "db2: [0.00348566 0.00416834 0.00501544]\n",
      "dW3: [[0.03348946 0.03548119 0.02795303]]\n",
      "db3: [0.04514462]\n"
     ]
    }
   ],
   "source": [
    "def model_gradients(X_train, Y_train, W2, b2, W3, b3, activation, activation_derivative):\n",
    "    num_data_points = len(X_train)\n",
    "    dW2 = np.zeros_like(W2)\n",
    "    db2 = np.zeros_like(b2)\n",
    "    dW3 = np.zeros_like(W3)\n",
    "    db3 = np.zeros_like(b3)\n",
    "    for point, label in zip(X_train, Y_train):\n",
    "        temp_dW2, temp_db2, temp_dW3, temp_db3 = backpropagation(point, label, W2, b2, W3, b3, activation, activation_derivative)\n",
    "        dW2 += temp_dW2\n",
    "        db2 += temp_db2\n",
    "        dW3 += temp_dW3\n",
    "        db3 += temp_db3\n",
    "    dW2 = dW2 / num_data_points\n",
    "    db2 = db2 / num_data_points\n",
    "    dW3 = dW3 / num_data_points\n",
    "    db3 = db3 / num_data_points\n",
    "\n",
    "    return dW2, db2, dW3, db3\n",
    "\n",
    "\n",
    "dW2, db2, dW3, db3 = model_gradients(train_points, train_labels, W2, b2, W3, b3, activation, activation_derivative)\n",
    "print(f'dW2: {dW2}\\ndb2: {db2}\\ndW3: {dW3}\\ndb3: {db3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform gradient descent to update your model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41309675 0.48482366]\n",
      " [0.6643742  0.93509573]\n",
      " [0.08014594 0.90636683]] [0.64206805 0.61634558 0.27245124] [[0.40400426 0.55206189 0.47237379]] [0.69449319] \n",
      "\n",
      "(array([[0.41281475, 0.48476872],\n",
      "       [0.66403981, 0.93503304],\n",
      "       [0.07974123, 0.90628492]]), array([0.64171948, 0.61592874, 0.2719497 ]), array([[0.40065531, 0.54851377, 0.46957849]]), array([0.68997873]))\n"
     ]
    }
   ],
   "source": [
    "def model_update(W2, b2, W3, b3, dW2, db2, dW3, db3, learning_rate):\n",
    "    W2 = W2 - (dW2 * learning_rate)\n",
    "    b2 = b2 - (db2 * learning_rate)\n",
    "    W3 = W3 - (dW3 * learning_rate)\n",
    "    b3 = b3 - (db3 * learning_rate)\n",
    "\n",
    "    return W2, b2, W3, b3\n",
    "\n",
    "\n",
    "print(W2, b2, W3, b3, '\\n')\n",
    "print(model_update(W2, b2, W3, b3, dW2, db2, dW3, db3, learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print checkpoints every 500 iterations which display the number of the current iteration and current value of the loss function and accuracy of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss: 0.12425056844271287, Accuracy: 50.000000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.40899815, 0.47199655],\n",
       "        [0.62793255, 0.93639899],\n",
       "        [0.00951986, 0.92166   ]]),\n",
       " array([0.62290987, 0.58182983, 0.21972541]),\n",
       " array([[-0.12051936,  0.01549722,  0.18721361]]),\n",
       " array([-0.02304137]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_train(X, Y, W2, b2, W3, b3, activation, activation_derivative, learning_rate, batch_size=32, epochs = 10, metrics=['loss', 'accuracy']):\n",
    "    num_training_points = len(X)\n",
    "    for i in range(epochs):\n",
    "        dW2, db2, dW3, db3 = model_gradients(X, Y, W2, b2, W3, b3, activation, activation_derivative)\n",
    "        W2, b2, W3, b3 = model_update(W2, b2, W3, b3, dW2, db2, dW3, db3, learning_rate)\n",
    "        if (i + 1) % 500 == 0:\n",
    "            total_loss = 0\n",
    "            num_predictions_correct = 0\n",
    "            for point, label in zip(X, Y):\n",
    "                A3 = forward_pass(point, W2, b2, W3, b3, activation)[-1]\n",
    "                prediction_loss = loss(label, A3)\n",
    "                label_prediction = np.round(A3)\n",
    "                if label_prediction == label:\n",
    "                    num_predictions_correct += 1\n",
    "                total_loss += prediction_loss\n",
    "            mean_loss = total_loss / num_training_points\n",
    "            accuracy = num_predictions_correct / num_training_points\n",
    "            print(f'Epoch {i + 1}, Loss: {mean_loss}, Accuracy: {accuracy:%}')\n",
    "\n",
    "    return W2, b2, W3, b3\n",
    "\n",
    "\n",
    "model_train(train_points, train_labels, W2, b2, W3, b3, activation, activation_derivative, learning_rate, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss: 0.12403410131506747, Accuracy: 65.000000%\n",
      "Epoch 1000, Loss: 0.12277134297092, Accuracy: 85.000000%\n",
      "Epoch 1500, Loss: 0.12048129117914182, Accuracy: 95.000000%\n",
      "Epoch 2000, Loss: 0.11619179769750135, Accuracy: 100.000000%\n",
      "Epoch 2500, Loss: 0.1085113812221464, Accuracy: 100.000000%\n",
      "Epoch 3000, Loss: 0.09665218823015378, Accuracy: 100.000000%\n",
      "Epoch 3500, Loss: 0.08183207536923273, Accuracy: 100.000000%\n",
      "Epoch 4000, Loss: 0.06679267350697833, Accuracy: 100.000000%\n",
      "Epoch 4500, Loss: 0.053828216646160984, Accuracy: 100.000000%\n",
      "Epoch 5000, Loss: 0.043642056136121946, Accuracy: 100.000000%\n",
      "W2: [[ 0.98433172 -0.11247614]\n",
      " [-2.64653082  2.85032192]\n",
      " [ 1.4853448  -0.93219137]]\n",
      "b2: [ 0.73888995  0.2756939  -0.02145567]\n",
      "W3: [[-0.77503827  4.07276656 -1.78498958]]\n",
      "b3: [-0.24617881]\n"
     ]
    }
   ],
   "source": [
    "W2, b2, W3, b3 = model_compile(num_input, num_hidden, num_output, activation, learning_rate)\n",
    "\n",
    "\n",
    "W2, b2, W3, b3 = model_train(train_points, train_labels, W2, b2, W3, b3, activation, activation_derivative, learning_rate, 5000)\n",
    "\n",
    "print(f'W2: {W2}\\nb2: {b2}\\nW3: {W3}\\nb3: {b3}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
